# Attention mechanism

![Sinusoidal encoding of spatial positions or times](assets/sinusoidal.svg)

A short introduction to attention in deep neural networks is provided.
[The notebook](notebooks/intro.ipynb) discusses the most important components of the transformer architecture.
The inputs and outputs of an attention operation are investigated in [another notebook](notebooks/shapes.ipynb).

